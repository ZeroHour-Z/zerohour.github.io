---
title: "CIKM25-MME-SID"
publishDate: 2025-09-05
updatedDate: 2025-09-06
description: 'Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic ID'
tags:
  - CIKM25
  - MME-SID
  - Session-Based Recommendation
---

 
## 1. 背景

序列推荐旨在根据用户的历史互动建模兴趣演化，从而预测下一次交互。近年来，LLM 被用于将用户历史转成“可读的语义序列”，让模型理解上下文并进行推荐；同时，传统推荐中的协作嵌入与多模态信号（文本、图像等）也被证明对提升判别性至关重要。

## 2. 研究问题

- **嵌入崩溃（Embedding Collapse）**：当将预训练的协作嵌入（如传统推荐模型学到的 item 向量）与 LLM 融合时，丰富的高维协作信息在联合训练/对齐过程中被过度平滑，造成不同物品的向量难以区分，进而削弱推荐判别性。
- **灾难性遗忘（Catastrophic Forgetting）**：在采用语义 ID（Semantic ID，通常由量化模型如 VQ-VAE 产生）来让 LLM 以“词元序列”的方式理解物品时，LLM 在学习新表征（语义 ID）的同时容易遗忘量化嵌入中蕴含的物品语义与结构信息，导致协同与语义两类知识无法兼得。
- **多模态对齐难题**：不同模态（ID、文本、图像等）既要保持各自模态内的距离结构，又要在模态间建立可对比、可迁移的相关性；常规对齐容易牺牲其一。

（通俗来说）
- 我觉得就是把“老经验的向量表示”和“会讲人话的大模型”硬拧一起，容易把味道搅没（崩溃）或学新忘旧（遗忘）。
- 不同信息源像“文字、图片、ID”彼此说话口音不同，既要保留各自特点，又要能互相听懂。

## 3. 方法（MME-SID）

- **提出 MME-SID 框架**：在 Llama3-8B-instruct 等 LLM 基础上，联合使用多模态嵌入与语义 ID/量化嵌入，既保留协同与视觉/文本等模态的判别性，又让 LLM 利用语境理解进行序列预测，从源头缓解嵌入崩溃与遗忘问题。

（通俗来说）
- 让模型“一手抓语境，一手抓结构”，既听得懂人话（语义 ID），也不忘老手艺（协作/量化向量和多模态）。

## 4. 关键模块：MM-RQ-VAE（MMD + 对比）

- 用重建损失对齐各模态，保持模态内的距离结构与几何形状；
- 用对比学习在模态间建立对应关系，提升跨模态一致性与检索能力；
- 用最大平均差异（MMD）进行分布级约束，稳定对齐并抑制表示塌缩与模式偏移。

（通俗来说）
- 重建损失像“描摹原样”，保证每种模态自己的形状不变形；
- 对比学习像“拉近同一商品的不同描述”，让跨模态能对上号；
- MMD 像“形状守护器”，防止所有表示挤成一团。

### RQ-VAE 原理详解（补充）

- 核心思想：用“残差式多级量化”把连续向量离散化，同时尽量保留原始几何结构。
- 组成
  - 编码器（Encoder）：将多模态特征映射为连续隐向量 $z$。
  - 多级残差量化（Residual Quantization）：
    1) 第1级用码本 C1 对 $z$ 做最近邻量化，得到 $q_1$，并计算残差 $r_1 = z - q_1$；
    2) 第2级用码本 C2 对 $r_1$ 再量化，得 $q_2$，残差 $r_2 = r_1 - q_2$；
    3) 重复 K 级，最终量化向量为 $q = \sum_{k=1}^{K} q_k$（每级一组“codes”）；
    4) 与普通 VQ-VAE 不同，RQ-VAE 用多级小码本叠加，容量更大、重建更精细。
  - 解码器（Decoder）：用量化后的 $q$ 重建输入模态（文本/图像/协作等），对齐到统一表征空间。
- 训练目标（与本文设计呼应）
  - 重建损失：让解码后的模态尽可能还原输入，保留模态内距离关系；
  - 码本承诺/回拉损失：稳定码本更新，避免“码字不动、编码器逃逸”；
  - 对比损失：同一物品跨模态靠近、不同物品分离，建立模态间可比性；
  - 分布对齐（MMD）：在分布层面稳定对齐、抑制塌缩；
  - 防遗忘（蒸馏/一致性）：保持语义ID与量化嵌入的一致，使 LLM 学新不忘旧。

（通俗来说）
- 把“大文件”分多次更细地压缩，每次都补一点，再还原时能更像原样；这样既有“离散ID”可读，又保留“向量几何”不丢。

### 图片导读（论文两张关键图）

- 图1 整体框架（MME-SID Overview）
  - 左侧：多模态输入（文本、图像、协作）经各自编码器抽取特征；
  - 中部：MM-RQ-VAE 进行重建与残差量化，对齐多模态；并用对比学习拉近同物、拉远异物；
  - 右侧：将物品映射为语义ID序列，和对齐后的量化/多模态表征一起，输入 LLM 做序列建模与下一物品预测；
  - 外层：MMD 等正则稳定分布对齐，整体端到端优化。
  - 读图要点：注意“语义ID通道”和“向量通道”是并行互补的，不是二选一。

- 图2 MM-RQ-VAE 结构（Residual Quantization）
  - 编码器输出 $z$ → 第1级码本近邻查找 → 得 $q_1$ 与残差 $r_1$；
  - 残差 $r_1$ → 第2级码本量化 → 得 $q_2$ 与 $r_2$；…… 迭代 K 级；
  - 将 $q_1 + q_2 + \cdots + q_K$ 作为量化表示 $q$，输入解码器做重建；
  - 训练同时包含重建/承诺损失、对比损失与 MMD；
  - 读图要点：每一级像“补丁”，逐步修正误差，码本大小可控而表达力累加。

