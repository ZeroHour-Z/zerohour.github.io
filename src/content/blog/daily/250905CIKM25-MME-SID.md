---
title: "CIKM25-MME-SID"
publishDate: 2025-09-05
updatedDate: 2025-09-06
description: 'Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic ID'
tags:
  - CIKM25
  - MME-SID
  - Session-Based Recommendation
---

 
## 1. 背景

序列推荐旨在根据用户的历史互动建模兴趣演化，从而预测下一次交互。近年来，LLM 被用于将用户历史转成“可读的语义序列”，让模型理解上下文并进行推荐；同时，传统推荐中的协作嵌入与多模态信号（文本、图像等）也被证明对提升判别性至关重要。

## 2. 研究问题

- **嵌入崩溃（Embedding Collapse）**：当将预训练的协作嵌入（如传统推荐模型学到的 item 向量）与 LLM 融合时，丰富的高维协作信息在联合训练/对齐过程中被过度平滑，造成不同物品的向量难以区分，进而削弱推荐判别性。[参考：`https://hjfy.top/arxiv/2509.02017`]
- **灾难性遗忘（Catastrophic Forgetting）**：在采用语义 ID（Semantic ID，通常由量化模型如 VQ-VAE 产生）来让 LLM 以“词元序列”的方式理解物品时，LLM 在学习新表征（语义 ID）的同时容易遗忘量化嵌入中蕴含的物品语义与结构信息，导致协同与语义两类知识无法兼得。[参考：`https://hjfy.top/arxiv/2509.02017`]
- **多模态对齐难题**：不同模态（ID、文本、图像等）既要保持各自模态内的距离结构，又要在模态间建立可对比、可迁移的相关性；常规对齐容易牺牲其一。[参考：`https://hjfy.top/arxiv/2509.02017`]

（通俗来说）
- 我觉得就是把“老经验的向量表示”和“会讲人话的大模型”硬拧一起，容易把味道搅没（崩溃）或学新忘旧（遗忘）。
- 不同信息源像“文字、图片、ID”彼此说话口音不同，既要保留各自特点，又要能互相听懂。

## 3. 方法（MME-SID）

- **提出 MME-SID 框架**：在 Llama3-8B-instruct 等 LLM 基础上，联合使用多模态嵌入与语义 ID/量化嵌入，既保留协同与视觉/文本等模态的判别性，又让 LLM 利用语境理解进行序列预测，从源头缓解嵌入崩溃与遗忘问题。[参考：`https://hjfy.top/arxiv/2509.02017`]

（通俗来说）
- 让模型“一手抓语境，一手抓结构”，既听得懂人话（语义 ID），也不忘老手艺（协作/量化向量和多模态）。

## 4. 关键模块：MM-RQ-VAE（MMD + 对比）

- 用重建损失对齐各模态，保持模态内的距离结构与几何形状；
- 用对比学习在模态间建立对应关系，提升跨模态一致性与检索能力；
- 用最大平均差异（MMD）进行分布级约束，稳定对齐并抑制表示塌缩与模式偏移。[参考：`https://hjfy.top/arxiv/2509.02017`]

（通俗来说）
- 重建损失像“描摹原样”，保证每种模态自己的形状不变形；
- 对比学习像“拉近同一商品的不同描述”，让跨模态能对上号；
- MMD 像“形状守护器”，防止所有表示挤成一团。

### RQ-VAE 原理详解（补充）

- 核心思想：用“残差式多级量化”把连续向量离散化，同时尽量保留原始几何结构。
- 组成
  - 编码器（Encoder）：将多模态特征映射为连续隐向量 $z$。
  - 多级残差量化（Residual Quantization）：
    1) 第1级用码本 C1 对 $z$ 做最近邻量化，得到 $q_1$，并计算残差 $r_1 = z - q_1$；
    2) 第2级用码本 C2 对 $r_1$ 再量化，得 $q_2$，残差 $r_2 = r_1 - q_2$；
    3) 重复 K 级，最终量化向量为 $q = \sum_{k=1}^{K} q_k$（每级一组“codes”）；
    4) 与普通 VQ-VAE 不同，RQ-VAE 用多级小码本叠加，容量更大、重建更精细。
  - 解码器（Decoder）：用量化后的 $q$ 重建输入模态（文本/图像/协作等），对齐到统一表征空间。
- 训练目标（与本文设计呼应）
  - 重建损失：让解码后的模态尽可能还原输入，保留模态内距离关系；
  - 码本承诺/回拉损失：稳定码本更新，避免“码字不动、编码器逃逸”；
  - 对比损失：同一物品跨模态靠近、不同物品分离，建立模态间可比性；
  - 分布对齐（MMD）：在分布层面稳定对齐、抑制塌缩；
  - 防遗忘（蒸馏/一致性）：保持语义ID与量化嵌入的一致，使 LLM 学新不忘旧。

（通俗来说）
- 把“大文件”分多次更细地压缩，每次都补一点，再还原时能更像原样；这样既有“离散ID”可读，又保留“向量几何”不丢。

### 图片导读（论文两张关键图）

- 图1 整体框架（MME-SID Overview）
  - 左侧：多模态输入（文本、图像、协作）经各自编码器抽取特征；
  - 中部：MM-RQ-VAE 进行重建与残差量化，对齐多模态；并用对比学习拉近同物、拉远异物；
  - 右侧：将物品映射为语义ID序列，和对齐后的量化/多模态表征一起，输入 LLM 做序列建模与下一物品预测；
  - 外层：MMD 等正则稳定分布对齐，整体端到端优化。
  - 读图要点：注意“语义ID通道”和“向量通道”是并行互补的，不是二选一。

- 图2 MM-RQ-VAE 结构（Residual Quantization）
  - 编码器输出 $z$ → 第1级码本近邻查找 → 得 $q_1$ 与残差 $r_1$；
  - 残差 $r_1$ → 第2级码本量化 → 得 $q_2$ 与 $r_2$；…… 迭代 K 级；
  - 将 $q_1 + q_2 + \cdots + q_K$ 作为量化表示 $q$，输入解码器做重建；
  - 训练同时包含重建/承诺损失、对比损失与 MMD；
  - 读图要点：每一级像“补丁”，逐步修正误差，码本大小可控而表达力累加。

参考来源：`https://hjfy.top/arxiv/2509.02017`

## 5. 训练与推理策略

- **联合训练，防崩溃与防遗忘**：
  - 融合协作嵌入与量化嵌入时采用目标分解与约束，避免信息被平均化；
  - 学习语义 ID 的同时，通过共享/蒸馏与对比目标，保留量化嵌入中的知识；必要时使用适配器/低秩更新等低干扰方式，降低对 LLM 既有能力的影响。[参考：`https://hjfy.top/arxiv/2509.02017`]
- **推理落地到序列推荐**：
  - 将用户历史交互的语义化序列输入 LLM，同时融合多模态与协作信号，生成下一物品候选与评分，实现上下文理解与协同结构的协同决策。[参考：`https://hjfy.top/arxiv/2509.02017`]

（通俗来说）
- 训练时不给某一路信息“一家独大”，一边学新词（语义 ID）一边复习老知识（量化/协作），避免遗忘；
- 推理时就像“读用户历史故事 + 看图说话 + 借用人群规律”，合起来猜下一步最可能喜欢的物品。

## A. 术语与符号

- 用户序列：$S_{u} = [ i_{1}, i_{2}, \ldots, i_{T} ]$，按时间排序的物品交互序列。
- 协作嵌入：$e_{i}^{c}$，来源于协同信号/传统推荐模型的 item 向量。
- 多模态嵌入：$e_{i}^{txt}$, $e_{i}^{img}$ 等，来自文本、图像等模态。
- 语义 ID：$sid_{i} = [ t_{1}, \ldots, t_{K} ]$，将物品离散为若干 token 的短序列。
- 量化嵌入：$q_{i}$，由（残差）量化模型产生的 item 向量。

**代码嵌入（Code Embeddings）详解：**

代码嵌入不是"程序代码"，而是量化模型（如 VQ-VAE/RQ-VAE）训练出的"码本向量"：
- **来源**：量化模型把连续向量映射到离散码字，每个码字对应一个向量，这些向量就是"代码嵌入"
- **与语义ID的关系**：
  - 语义ID = 离散的"码字序列/索引"（如[1,5,3]），适合给LLM当token
  - 代码嵌入 = 这些码字在向量空间里的"向量表示"，包含几何结构与语义信息
- **现有问题**：方法常只保留"语义ID"给LLM，丢弃"代码嵌入"，导致灾难性遗忘（忘了量化阶段学到的向量知识）
- **本文做法**：同时用语义ID和代码嵌入，通过对齐/对比/正则避免"学新忘旧"

（通俗来说）
- 代码嵌入 = 商品的"详细档案"（包含颜色、味道、特征等）
- 语义ID = 商品的"编号"（如123）
- 现有方法 = 只记编号，扔了档案
- 本文工作 = 编号和档案都要，互相补充
- 可以把 $sid_{i}$ 当作"把商品变成几枚词"的做法，把 $q_{i}$ 当作"商品的紧凑向量指纹"。

## B. 问题形式化与输入输出

- 输入：用户历史 $S_{u}$，以及每个物品的多模态信息与协作/量化表示 $\{ e_{i}^{c}, e_{i}^{txt}, e_{i}^{img}, q_{i}, sid_{i} \}$。
- 模型：基于 LLM 的序列建模器，联合使用多模态与语义 ID/量化信号；MM-RQ-VAE 用于多模态对齐与量化。
- 输出：对候选集合的排序/打分，预测下一个交互物品 $i_{T+1}$ 的概率/排名。[参考：`https://hjfy.top/arxiv/2509.02017`]

（通俗来说）
- 把“用户过去看/买的列表”和“每个商品的文字/图片/向量指纹”一起交给模型，让它猜“下一件最可能感兴趣的商品”。

## C. 整体架构流程（文字版）

1) 多模态编码：得到文本、图像等模态的表示；收集合作嵌入与量化嵌入。
2) MM-RQ-VAE 对齐：重建各模态、对比跨模态、用 MMD 稳定分布与避免塌缩，得到对齐后的 item 表征。
3) 语义 ID 建模：将 item 映射为 token 序列，让 LLM 在“可读序列”上进行上下文推理。
4) 联合训练：引入防崩溃与防遗忘的目标，约束不同通道的贡献，保持知识互补。
5) 推理推荐：输入用户历史的语义化序列与对齐后的多模态/协作线索，输出候选排名。[参考：`https://hjfy.top/arxiv/2509.02017`]

（通俗来说）
- 可以理解成“多模态翻译器 + 记忆保护器 + 会讲人话的推理器”三件套串起来。

- 重建损失 $L_{rec}$：保持模态内结构，避免信息在编码/对齐时走样。
- 对比损失 $L_{contrast}$：同一物品不同模态更近，跨物品更远，建立跨模态可比性。
- MMD 正则 $L_{mmd}$：对齐表征分布，抑制表示塌缩、缓解模态偏移。
- 防遗忘目标 $L_{distill} / L_{consistency}$：对语义 ID 学习时蒸馏/一致性约束，保留量化嵌入知识。
- 总体目标：
$$
L = L_{rec} + L_{contrast} + \lambda\, L_{mmd} + \mu\, L_{distill}
$$
（符号示意，具体权重与实现以论文为准）。[参考：`https://hjfy.top/arxiv/2509.02017`]

（通俗来说）
- 重建像“按原样复刻”，对比像“同物收拢、异物展开”，MMD 像“形状守护”，蒸馏像“别把老本事忘了”。

## 6. 实验要点与结论

- 论文报告显示：在多组序列推荐基准上，MME-SID 相较于仅用 LLM 序列化或仅用协作/多模态的方案取得更优结果；加入 MM-RQ-VAE 与联合目标后，泛化更稳健、对齐更充分。
- 消融实验（论文中给出）表明：去掉任一关键损失项（如对比/MMD/蒸馏）都会削弱性能，验证各组件的必要性。[参考：`https://hjfy.top/arxiv/2509.02017`]

（通俗来说）
- “三件套”缺一不可：既要会对齐、也要会记忆，还要会说“人话”。

## 7. 适用场景与局限

- 资源需求：LLM 与多模态编码会提升训练/推理成本，需按业务量级评估。
- 数据依赖：多模态质量与协作信号稀疏度会影响收益；冷启动仍需额外机制。
- 适用性：更适合有文本/图片商品素材与可获得协作信号的推荐场景。[参考：`https://hjfy.top/arxiv/2509.02017`]

（通俗来说）
- 模型强但“吃料多、耗能高”，素材越丰富、用户行为越真实，越能显出优势。

## 8. 快速复现清单（实践向）

- 准备数据：用户序列、文本与图片素材、协作嵌入或可训练其来源的数据。
- 预处理：文本/图像编码；语义 ID 与量化嵌入的生成或加载。
- 模型搭建：LLM 序列建模 + MM-RQ-VAE 对齐模块；支持多损失联合训练。
- 训练要点：逐步打开损失项与权重；监控塌缩迹象（向量方差/相似度分布）。
- 评测指标：常见 Top-K 指标（Recall/NDCG/HitRate 等），并做消融对照。
- 推理部署：缓存多模态与量化表示，结合检索召回与重排策略，控制延迟。[参考：`https://hjfy.top/arxiv/2509.02017`]

（通俗来说）
- 按“数据→表征→对齐→训练→评测→上线”的链条，一步步搭起来即可。

## 参考

- 论文页面：`https://hjfy.top/arxiv/2509.02017`
