---
title: "PaperReading2"
publishDate: 2025-11-9
description: 'Paper Reading on Multi-behavior Recommendation'
tags:
  - PaperReading
  - Sequential Recommendation
  - Multi-behavior
---

# MBSR: A Survey on Multi-Behavior Sequential Recommendation

## Motivation

如何处理序列和多行为？
- 现实推荐场景中存在多种行为，SBR 不能利用不同行为信号
- 单一隐式反馈易遭遇数据稀疏与冷启动，多行为可提供更完整的用户意图线索
- 异质行为引入顺序关系后，如何同时建模长短期偏好成为新挑战

1. **异质行为反馈的序列建模**：行为语义不一、信号强弱不同，意图存在不确定性
2. **用户行为之间的关系建模**：需要捕捉行为间的转移模式
3. **长短期偏好联合建模**：同时兼顾用户稳定兴趣与短期兴趣，避免遗忘
4. **噪声与偏差**：未发生行为不等于负反馈，序列中还可能存在曝光偏差与误操作噪声

## 分类

- 基于邻域的方法：利用邻域信息进行推荐，SBSR 拓展到 MBSR
- 基于矩阵分解的方法：迁移学习
- 基于深度学习的方法：RNN、GNN、Transformer、通用/混合结构

```
├── 技术视角
│   ├── 基于邻域的方法
│   ├── 基于矩阵分解的方法
│   └── 基于深度学习的方法
│       ├── RNN 架构
│       ├── GNN 架构
│       ├── Transformer 架构
│       ├── 通用方法
│       └── 混合方法
├── 数据视角
│   ├── (item, behavior) 对序列
│   ├── 行为特定的物品子序列
│   ├── 行为无关的物品序列
│   └── 行为序列
└── 建模视角
    ├── 局部建模（单个序列）
    └── 全局建模（所有序列）
```

### 邻域
BIS/ABIS（从 SBSR 扩展），通过双向物品相似度引入序列信息，难捕获高阶依赖，缺乏传递性

### 矩阵分解
TransRec++，构造行为转移向量（e2e、e2p、p2e、p2p），在隐空间中对齐前后行为

### 深度学习

**RNN**：梯度消失爆炸问题，效率低，难以预测未来序列
- **RLBL**
  - 行为转移矩阵（短期） + RNN（建模长期），物品嵌入 + 行为嵌入，再转移矩阵，最后进 RNN
  - 考虑了长短期、顺序、多行为，未考虑物品特征信息，且行为建模较简单
- **RIB**
  - GRU + 注意力机制（不同行为重要性），物品嵌入和行为嵌入拼接输入 GRU，h 输入注意力层，获得每个时间步的得分，最后输出层每个 h 都乘以对应的得分再求和
  - 使用嵌入表示行为类型，而且与物品嵌入直接拼接，可能无法捕捉真实的用户行为信息
- **BINN**
  - CLSTM/Bi-CLSTM，引入行为嵌入作为上下文门控，（物品，行为）序列输入
  - 两个模块：SBL 建模用户当前消费动机，PBL 用于学习用户长期偏好。SBL 中构建一个融入行为信息作为输入的 CLSTM，最后一步的隐状态输出就是消费动机。PBL 中使用 Bi-CLSTM，同时考虑前向和后向输入序列，获得隐状态作为长期偏好。两个模块的隐状态拼接后输入输出层，获得用户偏好。
  - 把行为嵌入矩阵输入 CLSTM和Bi-CLSTM，改变了 LSTM 的内部结构，使 LSTM 适用于多行为序列
  - 问题同 RIB，直接在嵌入矩阵中表示多种用户的行为类型
- **IARS**
  - 四个模块：一个 RNN 编码器感知用户意图，三个解码器判断或预测用户意图，学习用户复杂意图
  - （物品，行为，类别）序列输入编码器，多个多行为 GRU 单元处理行为类型，捕捉用户的多种意图
  - 行为嵌入仅参与重置门和更新门的计算，可能不足以完整表示用户的全部行为信息
- **MBN**
  - 三个模块，购物车编码器，元多行为序列编码器，重复项感知编码器
  - 购物车编码器把物品表征用最大汇聚转成购物车表征
  - 元多行为序列编码器中，多个特定行为的物品子序列输入，经过 Behavior-RNN 学习特定行为，Meta-RNN 学习多行为序列的协同知识，Meta-RNN 学的表征返回 Behavior-RNN 层校准行为的建模
  - 重复项感知预测器，生成模式与重复模式相结合的概率函数用于预测下次购物车中每个物品的概率
  - 收集传播，复杂度
- **CBS**
  - LSTM，对更长的序列建模
- **DIPN**
  - GRU + 分层注意力机制，多任务模块

**GNN**

- **MGNN-SPred**
  - 全局图，节点是物品，边有两种类型：购买边和浏览边
  - 对每个物品节点，找到它的四种邻居：购买入边邻居、浏览入边邻居、购买出边邻居、浏览出边邻居，聚合邻居节点的嵌入
  
- **DMBGN**
  - 优惠券兑换预测
  - 以优惠券为中心节点，构建四个子图：
    - `atc+`：加购发生在优惠券使用之前的物品
    - `atc-`：加购发生在优惠券使用之后的物品
    - `ord+`：下单发生在优惠券使用之前的物品
    - `ord-`：下单发生在优惠券使用之后的物品
  - 通过时间关系区分"使用优惠券前/后"的行为，更精准地建模用户意图
  
- **GPG4HSR**：
  - **双图**：
    - 所有用户的行为转移模式（如"浏览→购买"的通用规律）
    - 单个用户的行为序列（捕捉个人偏好）
  - **融合**：可学习权重 $\gamma_u$ 
  
- **BGNN**：
  - **双通道**：目标通道（购买序列）和辅助通道（浏览序列）
  - **两种图**：
    - **同质行为转移图（HoBTG）**：同种行为内的转移（浏览→浏览，购买→购买）
    - **异质行为转移图（HeBTG）**：不同行为间的转移（浏览→购买）
  - 区分同种行为内的关系和跨行为的关系，更精细地建模

**Transformer**

- **DMT（Deep Multifaceted Transformers）**
  - Encoder 处理行为特定的物品序列（浏览序列、加购序列、下单序列）
  - Decoder以目标物品为 Query，从 Encoder 输出中提取相关信息
  - 
    - $\boldsymbol{F}_{\mathrm{e}} = \text{Encoder}(\text{PE}(\text{Em}(\mathcal{S}_\mathrm{e})))$
    - $\boldsymbol{E}_{\mathrm{e}} = \text{Decoder}(\boldsymbol{F}_{\mathrm{e}}, \text{PE}(V_{i}^{\text{target}}))$
  - 使用 MMoE 同时优化 CTR和 CVR
  - **偏差建模**：使用深度神经网络建模隐式反馈中的偏差（如位置偏差、邻近偏差）
  - 每个行为使用独立的 Transformer（参数不共享），但缺乏显式的跨行为关系建模

- **DFN（Deep Feedback Network）**
感觉这个比较有意思，区分了用户不喜欢的和没看到不知道喜不喜欢的东西 
  - 使用**显式负反馈去噪隐式负反馈**
    - 隐式正反馈（查看过）和显式负反馈（明确不喜欢）
    - 通过注意力机制对隐式负反馈进行去噪：
      - $\boldsymbol{f}_{\mathrm{ne}} = \text{attention}(\text{Em}(\mathcal{S}_{\mathrm{n}}), \boldsymbol{f}_{\mathrm{e}})$
      - $\boldsymbol{f}_{\mathrm{nd}} = \text{attention}(\text{Em}(\mathcal{S}_{\mathrm{n}}), \boldsymbol{f}_{\mathrm{d}})$
    - 最终将去噪后的表示与其他特征拼接，输入 Wide、FM、Deep 三个模块
  - DFN 使用注意力机制探索不同行为间的关系，而 DMT 缺乏这种显式建模

- **NextIP（Next Item and Purchase Prediction）**
  - **两个任务**
    1. **物品预测任务**：预测下一个交互的物品是什么，兴趣
    2. **购买预测任务**：预测用户是否会购买，不一定是兴趣？
  - **双输入模式**：
    - 行为特定的物品子序列
    - (item, behavior) 对序列，跨行为转换信息
  - **TBCG（Target-Behavior-aware Context Aggregator）**：
    - 以目标行为嵌入为 Query
    - 以各行为子序列的最近交互为 Key 和 Value
  - **购买预测任务**：
    - 使用行为感知的自注意力块，根据行为类型和行为距离进行掩码
    - 对比学习，将辅助行为但没购买表示作为负样本

- **MB-STR（Multi-Behavior Sequential Transformer Recommender）**
标准的 Transformer 位置编码只关心一个词在序列中的绝对或相对位置，但在多行为推荐中，行为类型是至关重要的上下文信息
  - 设计**新颖的位置编码函数**，专门用于建模多行为序列关系
  - **Method**：
    - 受 T5 启发，使用启发式分桶机制（heuristic bucketing mechanism）
    - 不仅考虑位置距离，还考虑行为类型对（如"浏览→购买"和"购买→浏览"的位置编码不同）
  - BA-Pred（Behavior Aware Prediction）模块
  类似 MMoE 的参数共享网络，包含两部分：参数共享的专家和行为特定的专家
    - 同时预测用户下一个交互的物品和行为类型
    - 参数共享的专家：学习所有行为背后的共同用户兴趣模式
    - 行为特定的专家：专注于学习每种行为类型特有的模式

- **FLAG（Feedback-aware Local and Global）**
用户的最终决策是由长期稳定的偏好，短期意图以及行为反馈本身的性质共同驱动的
  - **四模块设计**：
    1. **局部偏好建模**：FSAB，短期兴趣
    2. **全局偏好建模**：LAL，长期偏好
    3. **局部意图建模**：使用反馈感知的注意力层（FAL）建模用户的局部意图，预测用户在下一个时间步最可能采取的行动意图
    4. **预测模块**：融合三种表示进行预测
  - **FSAB（Feedback-aware Self-Attention Block）**：
  对自注意力机制进行改进，对不同类型的行为使用不同的权重矩阵
    - 输入物品嵌入 + 位置嵌入X
    - $\boldsymbol{Q} = \sum_{f \in \mathcal{F}}(\boldsymbol{X} \otimes \boldsymbol{M}_{f}) \boldsymbol{W}_{f q}$（对 K、V 类似）
  - **局部意图建模**：
    - 输入：物品嵌入 + 位置嵌入 + 行为嵌入
    - 以**下一个行为**作为 Query，揭示用户在下一时间步的意图
    - 公式：$\boldsymbol{o}_{u}^{t}=V_{i_{u}^{t}}+\boldsymbol{p}_{t}^{\prime}+F_{f_{u}^{t}}$
  - **ISG（Item Similarity Gating）模块**：
    - 平衡局部偏好和全局偏好
    - 使用可学习权重 $\lambda$ 动态调整
    - 最终表示：$\boldsymbol{z}_{t}=\boldsymbol{z}_{t}^{\mathrm{lgp}}+\boldsymbol{z}_{t}^{\mathrm{li}}$
  - **局限性**：在训练时使用下一个真实反馈作为 Query，可能导致数据偏差和过拟合；在冷启动场景下表现不佳

- **DUMN（Denoising User-aware Memory Network）**
多头自注意力网络 + 注意力网络 + 记忆网络

- **FeedRec（News Feed Recommendation）**
  - 新闻推荐

**通用/混合方法**
- **DeepRec**：联邦学习场景下的隐私保护推荐
- **MBHT/TGT**：结合 GNN 和 Transformer，分别建模长短期偏好

### 对比

| 架构 | 优点 | 缺点 | 场景 |
|------|------|--------|----------|
| RNN | 适合序列问题，能存储短期记忆 | 梯度消失/爆炸，效率低，难以预测未来序列 | 早期工作，短序列 |
| GNN | 能建模复杂关系，处理数据稀疏能力强 | 图构建复杂度高，行为类型增多时复杂度膨胀 | 需要高阶关系建模的场景 |
| Transformer | 并行训练，长程依赖，训练速度快 | 局部信息捕获能力弱于 RNN | 长序列 |
| 混合方法 | 结合多种技术优势，性能提升明显 | 参数多，训练复杂 | 对性能要求高的场景 |

**数据视角的影响：**
- **(item, behavior) 对序列**：保留完整的行为信息，适合需要显式建模行为转移的方法
- **行为特定的物品子序列**：分别处理不同行为，适合需要区分行为语义的方法
- **行为无关的物品序列**：忽略行为类型，适合行为信息不重要的场景

## 主要结论

### 发现
1. 大多数工作采用深度学习方法，传统方法少
2. Transformer 主流
3. 结合多种技术的混合方法在性能上往往更优
4. **数据视角影响建模**：不同的数据组织方式会影响模型的表达能力和计算复杂度

### 趋势
- 从单一架构到混合架构
- 从局部建模到局部+全局联合建模
- 从单一目标到多目标优化
- 从忽略噪声到显式去噪

### 未来研究方向

**数据层面：**
- 数据稀疏性、不平衡性、周期性和噪声的显式建模
- 如何整合物品类别、知识图谱等辅助信息

**技术层面：**
- 结合多种互补技术（RNN 的局部建模 + Transformer 的长程依赖）
- 提高效率，支持实时推荐
- 行为类型增多时的复杂度控制
- 提高模型泛化能力，适应不同领域数据

**优化目标：**
- 多目标优化（如同时优化点击率和转化率）
- 如何合理平衡不同目标

**大模型：**
- 如何利用 LLM 的文本理解能力建模用户和物品的文本信息
- 如何将多行为信息与文本信息协同融合

### 三个重要的实现细节

**行为转移向量的设计（TransRec++）**
- **细节：** 定义四种行为转移向量：$e2e$（浏览→浏览）、$e2p$（浏览→购买）、$p2e$（购买→浏览）、$p2p$（购买→购买）
- **公式：** $\tilde{U}_{u}^{(\ell) i_{u}^{t}}=U_{u}+U_{u}^{(\ell) b(i_{u}^{t-\ell}) 2 b(i_{u}^{t})}$
- **重要性：** 这是显式建模行为间关系的经典方法，后续很多深度学习方法都借鉴了这一思想

**CLSTM 中的行为嵌入门控（BINN）**
- **细节：** 在 LSTM 的输入门、遗忘门、输出门中都引入行为嵌入 $F_{f_u^t}$，使 LSTM 能够根据行为类型动态调整信息流
- **公式：** $\boldsymbol{i}_t = \sigma(\boldsymbol{W}_{\mathrm{vi}}V_{i_u^t}+\boldsymbol{W}_{\mathrm{hi}}\boldsymbol{h}_{t-1}+\boldsymbol{W}_{\mathrm{bi}} F_{f_u^t}+\boldsymbol{b}_{\mathrm{i}})$
- **重要性：** 这是将行为信息深度融入序列模型的关键设计，避免了简单拼接导致的表达能力不足

**全局图与个性化图的融合（GPG4HSR）**
- **细节：** 构建全局图捕获所有用户的行为转移模式，构建个性化图捕获单个用户的局部上下文，通过可学习的权重 $\gamma_u$ 融合
- **公式：** $\boldsymbol{h}_{v}=\gamma_{u} \boldsymbol{h}_{v}^{g}+\left(1-\gamma_{u}\right) \boldsymbol{h}_{v}^{u}$，其中 $\gamma_{u}=\sigma\left(\boldsymbol{W}_{g p}\left[\boldsymbol{h}_{v}^{g} ; \boldsymbol{h}_{v}^{u}\right]\right)$
- **重要性：** 这种设计同时利用了全局统计信息和个性化信息，是处理数据稀疏性的有效方法

### 其他有价值的解决思路

**因果推断与反事实学习**
- **思路：** 当前方法大多基于相关性建模，但推荐中存在大量混淆因子（如曝光偏差、选择偏差）。可以引入因果推断框架，通过反事实学习去除偏差，提高推荐的可信度
- **实现：** 使用倾向得分匹配、工具变量等方法，或者设计因果图模型显式建模因果关系

**强化学习与序列决策**
- **思路：** 将推荐视为序列决策问题，使用强化学习（RL）优化长期累积奖励。可以建模用户行为的动态演化，考虑推荐的长期影响
- **实现：** 使用 DQN、PPO 等算法，设计合适的状态空间（用户历史行为）、动作空间（推荐物品）、奖励函数（点击、购买等）

**对比学习与自监督学习**
- **思路：** 利用对比学习增强表示学习，通过构造正负样本对，学习更好的用户和物品表示。可以缓解数据稀疏问题
- **实现：** 
  - 数据增强：对同一用户的不同行为子序列作为正样本
  - 跨行为对比：同一物品的不同行为作为正样本
  - 时间对比：同一用户相邻时间窗口的行为作为正样本

**知识图谱增强**
- **思路：** 引入外部知识图谱（如物品属性、类别层次、实体关系），通过知识图谱嵌入增强物品表示，提供更丰富的语义信息
- **实现：** 使用 TransE、RotatE 等知识图谱嵌入方法，设计多任务学习框架同时优化推荐任务和知识图谱补全任务

**可解释性与注意力可视化**
- **思路：** 不仅使用注意力机制提高性能，还要利用注意力权重提供可解释性。可以可视化哪些行为、哪些物品对最终推荐贡献最大
- **实现：** 
  - 设计可解释的注意力机制（如稀疏注意力）
  - 提供推荐理由生成（如"因为您浏览了A，购买了B，所以推荐C"）
  - 与业务 KPI 对齐（如转化路径分析）

**跨域迁移学习**
- **思路：** 利用源域（如电商）的多行为数据预训练模型，迁移到目标域（如视频推荐），解决冷启动问题
- **实现：** 
  - 设计领域适配层，对齐不同域的特征空间
  - 使用对抗训练减少域间差异
  - 设计渐进式迁移策略

**动态图神经网络**
- **思路：** 用户-物品交互图是动态演化的，可以使用动态图神经网络（如 TGAT、DyRep）建模时序演化
- **实现：** 将时间信息编码到图结构中，使用时间感知的图卷积操作

**多模态融合**
- **思路：** 不仅利用行为序列，还整合物品的图像、文本描述、用户画像等多模态信息
- **实现：** 
  - 使用预训练的多模态模型（如 CLIP）提取特征
  - 设计多模态融合模块（如交叉注意力）
  - 考虑模态间的对齐和互补关系
